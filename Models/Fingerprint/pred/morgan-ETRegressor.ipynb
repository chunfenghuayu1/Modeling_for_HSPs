{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "pkg_rootdir = os.path.dirname(os.path.dirname(cur_dir))\n",
    "# print(pkg_rootdir)\n",
    "if pkg_rootdir not in sys.path:\n",
    "    sys.path.append(pkg_rootdir)\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.mol2fp import morgan_binary_features_generator\n",
    "fp_generator = morgan_binary_features_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:20] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:47:21] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_excel(\"../../Dataset/train_data.xlsx\",index_col=False)\n",
    "test=pd.read_excel(\"../../Dataset/test_data.xlsx\",index_col=False)\n",
    "out_test=pd.read_excel(\"../../Dataset/data_out_feats.xlsx\",index_col=False)\n",
    "X_train = [fp_generator(smi) for smi in train[\"smiles\"]]\n",
    "X_test = [fp_generator(smi) for smi in test[\"smiles\"]]\n",
    "X_out = [fp_generator(smi) for smi in out_test[\"smiles\"]]\n",
    "\n",
    "y_train_D=train['D']\n",
    "y_train_P=train['P']\n",
    "y_train_H=train['H']\n",
    "\n",
    "y_test_D=test['D']\n",
    "y_test_P=test['P']\n",
    "y_test_H=test['H']\n",
    "\n",
    "y_out_D=out_test['D']\n",
    "y_out_P=out_test['P']\n",
    "y_out_H=out_test['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Define the objective function for hyperparameter optimization\n",
    "def objective(params, X_train, y_train):\n",
    "  model = ExtraTreesRegressor(**params, random_state=42)\n",
    "  # Perform cross-validation and minimize the negative mean squared error\n",
    "  score = -np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "  return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [50, 100, 200]),\n",
    "    'max_depth': hp.choice('max_depth', [10, 20, 30]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10]),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4]),\n",
    "    'criterion': 'friedman_mse',\n",
    "    'bootstrap':True,\n",
    "    'oob_score': True\n",
    "}\n",
    "\n",
    "# Function to optimize and save best parameters\n",
    "def optimize_and_save(X_train, y_train, output_path):\n",
    "  trials = Trials()\n",
    "  best_params = fmin(fn=lambda params: objective(params, X_train, y_train), \n",
    "             space=space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "  \n",
    "  # Convert categorical parameters back to their original values\n",
    "  best_params['n_estimators'] = [50, 100, 200][best_params['n_estimators']]\n",
    "  best_params['max_depth'] = [10, 20, 30][best_params['max_depth']]\n",
    "  best_params['min_samples_split'] = [2, 5, 10][best_params['min_samples_split']]\n",
    "  best_params['min_samples_leaf'] = [1, 2, 4][best_params['min_samples_leaf']]\n",
    "  best_params['criterion'] = 'friedman_mse'\n",
    "  best_params['bootstrap'] = True\n",
    "  best_params['oob_score'] = True\n",
    "  \n",
    "  with open(output_path, 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "  \n",
    "  return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [11:54<00:00, 14.29s/trial, best loss: 0.8703249512125246]\n",
      "100%|██████████| 50/50 [18:05<00:00, 21.72s/trial, best loss: 7.937924117220845]\n",
      "100%|██████████| 50/50 [19:25<00:00, 23.32s/trial, best loss: 11.0165441355612]  \n"
     ]
    }
   ],
   "source": [
    "# Optimize and save parameters for D, P, and H\n",
    "best_params_D = optimize_and_save(X_train, y_train_D, './results/morgan/best_params_D.json')\n",
    "best_params_P = optimize_and_save(X_train, y_train_P, './results/morgan/best_params_P.json')\n",
    "best_params_H = optimize_and_save(X_train, y_train_H, './results/morgan/best_params_H.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Function to train model, get feature importance, and evaluate performance\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test,X_out,y_out, best_params):\n",
    "  # Train model with best hyperparameters\n",
    "  model = ExtraTreesRegressor(**best_params, random_state=42)\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  # Evaluate model\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  y_out_pred = model.predict(X_out)\n",
    "  \n",
    "  metrics = {\n",
    "    'train_r2': r2_score(y_train, y_train_pred),\n",
    "    'test_r2': r2_score(y_test, y_test_pred),\n",
    "    'out_r2': r2_score(y_out, y_out_pred),\n",
    "    'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "    'out_rmse': np.sqrt(mean_squared_error(y_out, y_out_pred)),\n",
    "    'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "    'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
    "    'out_mae': mean_absolute_error(y_out, y_out_pred),\n",
    "  \n",
    "  }\n",
    "  \n",
    "  # Save original and predicted data\n",
    "  train_results = pd.DataFrame({'y_train': y_train, 'y_train_pred': y_train_pred})\n",
    "  test_results = pd.DataFrame({'y_test': y_test, 'y_test_pred': y_test_pred})\n",
    "  out_results = pd.DataFrame({'y_out': y_out, 'y_out_pred': y_out_pred})\n",
    "\n",
    "  \n",
    "  return model,metrics,train_results, test_results,out_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9618956202245981,\n",
       " 'test_r2': 0.7814226146505492,\n",
       " 'out_r2': 0.6983169802898215,\n",
       " 'train_rmse': 0.3629927040758541,\n",
       " 'test_rmse': 0.8359207377077681,\n",
       " 'out_rmse': 0.765708242701564,\n",
       " 'train_mae': 0.2537196635670927,\n",
       " 'test_mae': 0.5601506487710544,\n",
       " 'out_mae': 0.588664702880925}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_D,metrics_D,train_results_D, test_results_D,out_results_D = train_and_evaluate(X_train, y_train_D, X_test, y_test_D,X_out,y_out_D, best_params_D)\n",
    "metrics_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9126146095832235,\n",
       " 'test_r2': 0.5545721998251523,\n",
       " 'out_r2': 0.47841915030192006,\n",
       " 'train_rmse': 1.2817684663465392,\n",
       " 'test_rmse': 2.7718883775168615,\n",
       " 'out_rmse': 3.823311795753223,\n",
       " 'train_mae': 0.9152498193507754,\n",
       " 'test_mae': 1.923162103937849,\n",
       " 'out_mae': 2.592588624028432}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_P,metrics_P,train_results_P, test_results_P,out_results_P = train_and_evaluate(X_train, y_train_P, X_test, y_test_P,X_out,y_out_P, best_params_P)\n",
    "metrics_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.947000358125516,\n",
       " 'test_r2': 0.7473570104775835,\n",
       " 'out_r2': 0.7367782433563308,\n",
       " 'train_rmse': 1.3404800015106961,\n",
       " 'test_rmse': 2.2371062872174123,\n",
       " 'out_rmse': 3.73824906314914,\n",
       " 'train_mae': 0.7953238334846969,\n",
       " 'test_mae': 1.5599048563357916,\n",
       " 'out_mae': 2.684249957494356}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_H,metrics_H,train_results_H, test_results_H,out_results_H = train_and_evaluate(X_train, y_train_H, X_test, y_test_H,X_out,y_out_H, best_params_H)\n",
    "metrics_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量保存 metrics 到 Excel 文件\n",
    "metrics_dict = {\n",
    "  \"Metrics_D\": metrics_D,\n",
    "  \"Metrics_P\": metrics_P,\n",
    "  \"Metrics_H\": metrics_H\n",
    "}\n",
    "\n",
    "output_path = \"./results/morgan/metrics_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "  for sheet_name, metrics in metrics_dict.items():\n",
    "    pd.DataFrame([metrics]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/morgan/train_results_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "  train_results_D.to_excel(writer, sheet_name=\"Train_Results_D\", index=False)\n",
    "  train_results_P.to_excel(writer, sheet_name=\"Train_Results_P\", index=False)\n",
    "  train_results_H.to_excel(writer, sheet_name=\"Train_Results_H\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/morgan/test_results_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "  test_results_D.to_excel(writer, sheet_name=\"Test_Results_D\", index=False)\n",
    "  test_results_P.to_excel(writer, sheet_name=\"Test_Results_P\", index=False)\n",
    "  test_results_H.to_excel(writer, sheet_name=\"Test_Results_H\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/morgan/out_results_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "  out_results_D.to_excel(writer, sheet_name=\"out_Results_D\", index=False)\n",
    "  out_results_P.to_excel(writer, sheet_name=\"out_Results_P\", index=False)\n",
    "  out_results_H.to_excel(writer, sheet_name=\"out_Results_H\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
