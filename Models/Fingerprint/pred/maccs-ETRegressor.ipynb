{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "pkg_rootdir = os.path.dirname(os.path.dirname(os.path.dirname(cur_dir)))\n",
    "# print(pkg_rootdir)\n",
    "if pkg_rootdir not in sys.path:\n",
    "    sys.path.append(pkg_rootdir)\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.mol2fp import maccs_features_generator\n",
    "\n",
    "fp_generator = maccs_features_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:20:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[17:20:14] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_excel(\"../../../Dataset/train_data.xlsx\", index_col=False)\n",
    "test = pd.read_excel(\"../../../Dataset/test_data.xlsx\", index_col=False)\n",
    "out_test = pd.read_excel(\"../../../Dataset/data_out_feats.xlsx\", index_col=False)\n",
    "X_train = [fp_generator(smi) for smi in train[\"smiles\"]]\n",
    "X_test = [fp_generator(smi) for smi in test[\"smiles\"]]\n",
    "X_out = [fp_generator(smi) for smi in out_test[\"smiles\"]]\n",
    "\n",
    "y_train_D = train[\"D\"]\n",
    "y_train_P = train[\"P\"]\n",
    "y_train_H = train[\"H\"]\n",
    "\n",
    "y_test_D = test[\"D\"]\n",
    "y_test_P = test[\"P\"]\n",
    "y_test_H = test[\"H\"]\n",
    "\n",
    "y_out_D = out_test[\"D\"]\n",
    "y_out_P = out_test[\"P\"]\n",
    "y_out_H = out_test[\"H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhyperopt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fmin, tpe, hp, Trials, STATUS_OK\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtraTreesRegressor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yuchen\\miniconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\ensemble\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Ensemble-based methods for classification, regression and anomaly detection.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bagging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaggingClassifier, BaggingRegressor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseEnsemble\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     ExtraTreesClassifier,\n\u001b[0;32m     10\u001b[0m     ExtraTreesRegressor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     RandomTreesEmbedding,\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yuchen\\miniconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClassifierMixin, RegressorMixin, _fit_context\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, r2_score\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier, DecisionTreeRegressor\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Bunch,\n\u001b[0;32m     21\u001b[0m     _safe_indexing,\n\u001b[0;32m     22\u001b[0m     check_random_state,\n\u001b[0;32m     23\u001b[0m     column_or_1d,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mask\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m indices_to_mask\n",
      "File \u001b[1;32mc:\\Users\\yuchen\\miniconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\tree\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Decision tree based models for classification and regression.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     BaseDecisionTree,\n\u001b[0;32m      8\u001b[0m     DecisionTreeClassifier,\n\u001b[0;32m      9\u001b[0m     DecisionTreeRegressor,\n\u001b[0;32m     10\u001b[0m     ExtraTreeClassifier,\n\u001b[0;32m     11\u001b[0m     ExtraTreeRegressor,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_graphviz, export_text, plot_tree\n\u001b[0;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseDecisionTree\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecisionTreeClassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport_text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\yuchen\\miniconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:40\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     _assert_all_finite_element_wise,\n\u001b[0;32m     34\u001b[0m     _check_n_features,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     validate_data,\n\u001b[0;32m     39\u001b[0m )\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _criterion, _splitter, _tree\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_criterion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Criterion\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Splitter\n",
      "File \u001b[1;32m_criterion.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._criterion\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_splitter.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._splitter\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._tree\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yuchen\\miniconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\neighbors\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kde\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lof\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalOutlierFactor\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nca\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeighborhoodComponentsAnalysis\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nearest_centroid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NearestCentroid\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_regression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNeighborsRegressor, RadiusNeighborsRegressor\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1138\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1078\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1507\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1479\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1615\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "# Define the objective function for hyperparameter optimization\n",
    "def objective(params, X_train, y_train):\n",
    "    model = ExtraTreesRegressor(**params, random_state=42)\n",
    "    # Perform cross-validation and minimize the negative mean squared error\n",
    "    score = -np.mean(\n",
    "        cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    )\n",
    "    return {\"loss\": score, \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [50, 100, 200]),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [5, 10, 15]),\n",
    "    \"min_samples_split\": hp.choice(\"min_samples_split\", [2, 5, 10]),\n",
    "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", [1, 2, 4]),\n",
    "    \"criterion\": \"friedman_mse\",\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": True,\n",
    "}\n",
    "\n",
    "\n",
    "# Function to optimize and save best parameters\n",
    "def optimize_and_save(X_train, y_train, output_path):\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn=lambda params: objective(params, X_train, y_train),\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=50,\n",
    "        trials=trials,\n",
    "    )\n",
    "\n",
    "    # Convert categorical parameters back to their original values\n",
    "    best_params[\"n_estimators\"] = [50, 100, 200][best_params[\"n_estimators\"]]\n",
    "    best_params[\"max_depth\"] = [5, 10, 15][best_params[\"max_depth\"]]\n",
    "    best_params[\"min_samples_split\"] = [2, 5, 10][best_params[\"min_samples_split\"]]\n",
    "    best_params[\"min_samples_leaf\"] = [1, 2, 4][best_params[\"min_samples_leaf\"]]\n",
    "    best_params[\"criterion\"] = \"friedman_mse\"\n",
    "    best_params[\"bootstrap\"] = True\n",
    "    best_params[\"oob_score\"] = True\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(best_params, f)\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:00<00:00,  2.40s/trial, best loss: 0.7071983305775384]\n"
     ]
    }
   ],
   "source": [
    "# Optimize and save parameters for D, P, and H\n",
    "best_params_D = optimize_and_save(\n",
    "    X_train, y_train_D, \"./results/maccs/best_params_D.json\"\n",
    ")\n",
    "best_params_P = optimize_and_save(\n",
    "    X_train, y_train_P, \"./results/maccs/best_params_P.json\"\n",
    ")\n",
    "best_params_H = optimize_and_save(\n",
    "    X_train, y_train_H, \"./results/maccs/best_params_H.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to train model, get feature importance, and evaluate performance\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, X_out, y_out, best_params):\n",
    "    # Train model with best hyperparameters\n",
    "    model = ExtraTreesRegressor(**best_params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_out_pred = model.predict(X_out)\n",
    "\n",
    "    metrics = {\n",
    "        \"train_r2\": r2_score(y_train, y_train_pred),\n",
    "        \"test_r2\": r2_score(y_test, y_test_pred),\n",
    "        \"out_r2\": r2_score(y_out, y_out_pred),\n",
    "        \"train_rmse\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"test_rmse\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"out_rmse\": np.sqrt(mean_squared_error(y_out, y_out_pred)),\n",
    "        \"train_mae\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"test_mae\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"out_mae\": mean_absolute_error(y_out, y_out_pred),\n",
    "    }\n",
    "\n",
    "    # Save original and predicted data\n",
    "    train_results = pd.DataFrame({\"y_train\": y_train, \"y_train_pred\": y_train_pred})\n",
    "    test_results = pd.DataFrame({\"y_test\": y_test, \"y_test_pred\": y_test_pred})\n",
    "    out_results = pd.DataFrame({\"y_out\": y_out, \"y_out_pred\": y_out_pred})\n",
    "\n",
    "    return model, metrics, train_results, test_results, out_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9573135214271805,\n",
       " 'test_r2': 0.7552113821003719,\n",
       " 'out_r2': 0.7210947788024502,\n",
       " 'train_rmse': 0.3841984532706982,\n",
       " 'test_rmse': 0.8846227342728824,\n",
       " 'out_rmse': 0.7453699635092684,\n",
       " 'train_mae': 0.2700300482460552,\n",
       " 'test_mae': 0.5262260131887451,\n",
       " 'out_mae': 0.5603292766613117}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_D, metrics_D, train_results_D, test_results_D, out_results_D = train_and_evaluate(\n",
    "    X_train, y_train_D, X_test, y_test_D, X_out, y_out_D, best_params_D\n",
    ")\n",
    "metrics_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.8709640469249817,\n",
       " 'test_r2': 0.604097658509489,\n",
       " 'out_r2': 0.6794659213108213,\n",
       " 'train_rmse': 1.5575626864473868,\n",
       " 'test_rmse': 2.6132509274938047,\n",
       " 'out_rmse': 2.9773691020130606,\n",
       " 'train_mae': 1.1360364600790729,\n",
       " 'test_mae': 1.849715944534528,\n",
       " 'out_mae': 1.7009924012127946}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_P, metrics_P, train_results_P, test_results_P, out_results_P = train_and_evaluate(\n",
    "    X_train, y_train_P, X_test, y_test_P, X_out, y_out_P, best_params_P\n",
    ")\n",
    "metrics_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9650438146807624,\n",
       " 'test_r2': 0.8220403589970205,\n",
       " 'out_r2': 0.9059065432238286,\n",
       " 'train_rmse': 1.08864401221389,\n",
       " 'test_rmse': 1.8775596914534183,\n",
       " 'out_rmse': 2.2600014981382017,\n",
       " 'train_mae': 0.6920797493279757,\n",
       " 'test_mae': 1.299877506555218,\n",
       " 'out_mae': 1.794405081294792}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_H, metrics_H, train_results_H, test_results_H, out_results_H = train_and_evaluate(\n",
    "    X_train, y_train_H, X_test, y_test_H, X_out, y_out_H, best_params_H\n",
    ")\n",
    "metrics_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量保存 metrics 到 Excel 文件\n",
    "metrics_dict = {\"Metrics_D\": metrics_D, \"Metrics_P\": metrics_P, \"Metrics_H\": metrics_H}\n",
    "\n",
    "output_path = \"./results/maccs/metrics_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for sheet_name, metrics in metrics_dict.items():\n",
    "        pd.DataFrame([metrics]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/maccs/train_results_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    train_results_D.to_excel(writer, sheet_name=\"Train_Results_D\", index=False)\n",
    "    train_results_P.to_excel(writer, sheet_name=\"Train_Results_P\", index=False)\n",
    "    train_results_H.to_excel(writer, sheet_name=\"Train_Results_H\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/maccs/test_results_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    test_results_D.to_excel(writer, sheet_name=\"Test_Results_D\", index=False)\n",
    "    test_results_P.to_excel(writer, sheet_name=\"Test_Results_P\", index=False)\n",
    "    test_results_H.to_excel(writer, sheet_name=\"Test_Results_H\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/maccs/out_results_summary.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    out_results_D.to_excel(writer, sheet_name=\"out_Results_D\", index=False)\n",
    "    out_results_P.to_excel(writer, sheet_name=\"out_Results_P\", index=False)\n",
    "    out_results_H.to_excel(writer, sheet_name=\"out_Results_H\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
