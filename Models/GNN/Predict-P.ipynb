{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "pkg_rootdir = os.path.dirname(os.path.dirname(cur_dir))\n",
    "if pkg_rootdir not in sys.path:\n",
    "    sys.path.append(pkg_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch_geometric import seed_everything\n",
    "import torch\n",
    "from Utils.mol2graph import data_process\n",
    "from Utils.evaluate_gnn import model_test, model_val, EarlyStopping\n",
    "from torch import nn\n",
    "from Utils.models import AttentiveFPModel\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_paramas = {\n",
    "    \"hidden_dim\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_timesteps\": 10,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:56:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:56:41] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_excel(\"../../Dataset/train_data.xlsx\", index_col=False)\n",
    "test = pd.read_excel(\"../../Dataset/test_data.xlsx\", index_col=False)\n",
    "out_test = pd.read_excel(\"../../Dataset/data_out_feats.xlsx\", index_col=False)\n",
    "\n",
    "train_loader = data_process(\n",
    "    train, batch_size=att_paramas[\"batch_size\"], label_str=\"P\", shuffle=True\n",
    ")\n",
    "test_loader = data_process(test, batch_size=len(test), label_str=\"P\", shuffle=False)\n",
    "out_test_loader = data_process(\n",
    "    out_test, batch_size=len(out_test), label_str=\"P\", shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_values = []  # 替换为训练集 RMSE 的记录值\n",
    "val_rmse_values = []  # 替换为验证集 RMSE 的记录值\n",
    "test_rmse_values = []  # 替换为测试集 RMSE 的记录值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train      - R2: 0.8937, RMSE: 1.4135, MAE: 1.0079\n",
      "  Test      - R2: 0.6871, RMSE: 2.3231, MAE: 1.5747\n",
      "  Out       - R2: 0.8039, RMSE: 2.3288, MAE: 1.5643\n"
     ]
    }
   ],
   "source": [
    "model = AttentiveFPModel(\n",
    "    input_dim=72,\n",
    "    hidden_dim=att_paramas[\"hidden_dim\"],\n",
    "    output_dim=1,\n",
    "    num_layers=att_paramas[\"num_layers\"],\n",
    "    dropout=att_paramas[\"dropout\"],\n",
    "    num_timesteps=att_paramas[\"num_timesteps\"],\n",
    ").to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"./ATT_P_\" + \".pth\"))\n",
    "train_r2, train_mae, train_rmse, train_y_true, train_y_pred = model_test(\n",
    "    model, train_loader, device\n",
    ")\n",
    "\n",
    "test_r2, test_mae, test_rmse, test_y_true, test_y_pred = model_test(\n",
    "    model, test_loader, device\n",
    ")\n",
    "\n",
    "out_r2, out_mae, out_rmse, out_y_true, out_y_pred = model_test(\n",
    "    model, out_test_loader, device\n",
    ")\n",
    "\n",
    "train_rmse_values.append(train_rmse)\n",
    "\n",
    "val_rmse_values.append(test_rmse)\n",
    "\n",
    "test_rmse_values.append(out_rmse)\n",
    "\n",
    "# print(f\"Epoch {epoch:03d}:\")\n",
    "\n",
    "print(\n",
    "    f\"  Train      - R2: {train_r2:.4f}, RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}\"\n",
    ")\n",
    "\n",
    "print(f\"  Test      - R2: {test_r2:.4f}, RMSE: {test_rmse:.4f}, MAE: {test_mae:.4f}\")\n",
    "print(f\"  Out       - R2: {out_r2:.4f}, RMSE: {out_rmse:.4f}, MAE: {out_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {\"P\": train_y_true, \"P_pred\": train_y_pred}\n",
    "\n",
    "test = {\"test_y\": test_y_true, \"y_pred\": test_y_pred}\n",
    "\n",
    "out_test = {\"out_y\": out_y_true, \"out_y_pred\": out_y_pred}\n",
    "metrics = {\n",
    "    \"train_r2\": [train_r2],\n",
    "    \"test_r2\": [test_r2],\n",
    "    \"out_r2\": [out_r2],\n",
    "    \"train_rmse\": [train_rmse],\n",
    "    \"test_rmse\": [test_rmse],\n",
    "    \"out_rmse\": [out_rmse],\n",
    "    \"train_mae\": [train_mae],\n",
    "    \"test_mae\": [test_mae],\n",
    "    \"out_mae\": [out_mae],\n",
    "}\n",
    "\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)\n",
    "out_test = pd.DataFrame(out_test)\n",
    "metrics = pd.DataFrame(metrics)\n",
    "train.to_excel(\"./results/P/ATT_train_data.xlsx\", index=False)\n",
    "test.to_excel(\"./results/P/ATT_test_data.xlsx\", index=False)\n",
    "out_test.to_excel(\"./results/P/ATT_out_test_data.xlsx\", index=False)\n",
    "metrics.to_excel(\"./results/P/ATT_metrics.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
