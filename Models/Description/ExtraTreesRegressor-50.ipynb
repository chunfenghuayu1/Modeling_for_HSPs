{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_D = pd.read_excel(\n",
    "    \"../../Features/Results/feature_importance_D.xlsx\", index_col=False\n",
    ")\n",
    "\n",
    "\n",
    "feature_P = pd.read_excel(\n",
    "    \"../../Features/Results/feature_importance_P.xlsx\", index_col=False\n",
    ")\n",
    "\n",
    "\n",
    "feature_H = pd.read_excel(\n",
    "    \"../../Features/Results/feature_importance_H.xlsx\", index_col=False\n",
    ")\n",
    "\n",
    "\n",
    "# 获取前20个特征\n",
    "\n",
    "\n",
    "top_50_features_D = feature_D[:50][\"Feature\"]\n",
    "\n",
    "\n",
    "top_50_features_H = feature_H[:50][\"Feature\"]\n",
    "\n",
    "\n",
    "top_50_features_P = feature_P[:50][\"Feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 定义存储 JSON 数据的字典\n",
    "json_data = {}\n",
    "# 指定 JSON 文件所在的目录\n",
    "json_dir = \"../../Features/Results/\"\n",
    "# 遍历目录中的所有文件\n",
    "for file_name in os.listdir(json_dir):\n",
    "    if file_name.endswith(\".json\"):  # 检查文件是否为 JSON 文件\n",
    "        file_path = os.path.join(json_dir, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            json_data[file_name.replace(\".json\", \"\")] = json.load(file)\n",
    "\n",
    "best_params_D = json_data[\"best_params_D\"]\n",
    "best_params_P = json_data[\"best_params_P\"]\n",
    "best_params_H = json_data[\"best_params_H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"../../Dataset/train_data.xlsx\", index_col=False)\n",
    "test = pd.read_excel(\"../../Dataset/test_data.xlsx\", index_col=False)\n",
    "out_test = pd.read_excel(\"../../Dataset/data_out_feats.xlsx\", index_col=False)\n",
    "X_train_D = train[top_50_features_D]\n",
    "X_train_P = train[top_50_features_P]\n",
    "X_train_H = train[top_50_features_H]\n",
    "\n",
    "X_test_D = test[top_50_features_D]\n",
    "X_test_P = test[top_50_features_P]\n",
    "X_test_H = test[top_50_features_H]\n",
    "\n",
    "y_train_D = train[\"D\"]\n",
    "y_train_P = train[\"P\"]\n",
    "y_train_H = train[\"H\"]\n",
    "\n",
    "y_test_D = test[\"D\"]\n",
    "y_test_P = test[\"P\"]\n",
    "y_test_H = test[\"H\"]\n",
    "\n",
    "X_out_D = out_test[top_50_features_D]\n",
    "X_out_P = out_test[top_50_features_P]\n",
    "X_out_H = out_test[top_50_features_H]\n",
    "\n",
    "y_out_D = out_test[\"D\"]\n",
    "y_out_P = out_test[\"P\"]\n",
    "y_out_H = out_test[\"H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to train model, get feature importance, and evaluate performance\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, X_out, y_out, best_params):\n",
    "    # Train model with best hyperparameters\n",
    "    model = ExtraTreesRegressor(**best_params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_out_pred = model.predict(X_out)\n",
    "\n",
    "    metrics = {\n",
    "        \"train_r2\": r2_score(y_train, y_train_pred),\n",
    "        \"test_r2\": r2_score(y_test, y_test_pred),\n",
    "        \"out_r2\": r2_score(y_out, y_out_pred),\n",
    "        \"train_rmse\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"test_rmse\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"out_rmse\": np.sqrt(mean_squared_error(y_out, y_out_pred)),\n",
    "        \"train_mae\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"test_mae\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"out_mae\": mean_absolute_error(y_out, y_out_pred),\n",
    "    }\n",
    "\n",
    "    # Save original and predicted data\n",
    "    train_results = pd.DataFrame({\"y_train\": y_train, \"y_train_pred\": y_train_pred})\n",
    "    test_results = pd.DataFrame({\"y_test\": y_test, \"y_test_pred\": y_test_pred})\n",
    "    out_results = pd.DataFrame({\"y_out\": y_out, \"y_out_pred\": y_out_pred})\n",
    "\n",
    "    return model, metrics, train_results, test_results, out_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9695894270296452,\n",
       " 'test_r2': 0.8088155281005586,\n",
       " 'out_r2': 0.6290969094002017,\n",
       " 'train_rmse': 0.3242819299127081,\n",
       " 'test_rmse': 0.781787629271844,\n",
       " 'out_rmse': 0.859555238936426,\n",
       " 'train_mae': 0.23179972700489873,\n",
       " 'test_mae': 0.44754989662538874,\n",
       " 'out_mae': 0.6674641423237976}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_D, metrics_D, train_results_D, test_results_D, out_results_D = train_and_evaluate(\n",
    "    X_train_D, y_train_D, X_test_D, y_test_D, X_out_D, y_out_D, best_params_D\n",
    ")\n",
    "metrics_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.8866547293061107,\n",
       " 'test_r2': 0.6693586418815856,\n",
       " 'out_r2': 0.5552447048872282,\n",
       " 'train_rmse': 1.4597949924697378,\n",
       " 'test_rmse': 2.3881723516851165,\n",
       " 'out_rmse': 3.507164494971362,\n",
       " 'train_mae': 1.0684293908216256,\n",
       " 'test_mae': 1.7155853948486224,\n",
       " 'out_mae': 2.4534204693891897}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_P, metrics_P, train_results_P, test_results_P, out_results_P = train_and_evaluate(\n",
    "    X_train_P, y_train_P, X_test_P, y_test_P, X_out_P, y_out_P, best_params_P\n",
    ")\n",
    "metrics_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9738663780975396,\n",
       " 'test_r2': 0.8145000788859359,\n",
       " 'out_r2': 0.9062383946399588,\n",
       " 'train_rmse': 0.941290495287304,\n",
       " 'test_rmse': 1.9169238337525158,\n",
       " 'out_rmse': 2.2560126600260193,\n",
       " 'train_mae': 0.5749317148737327,\n",
       " 'test_mae': 1.2006718187687702,\n",
       " 'out_mae': 1.7840750583104836}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "model_H, metrics_H, train_results_H, test_results_H, out_results_H = train_and_evaluate(\n",
    "    X_train_H, y_train_H, X_test_H, y_test_H, X_out_H, y_out_H, best_params_H\n",
    ")\n",
    "metrics_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./SHAP/model_H_50.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(model_D, \"./SHAP/model_D_50.joblib\")\n",
    "dump(model_P, \"./SHAP/model_P_50.joblib\")\n",
    "dump(model_H, \"./SHAP/model_H_50.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量保存 metrics 到 Excel 文件\n",
    "metrics_dict = {\"Metrics_D\": metrics_D, \"Metrics_P\": metrics_P, \"Metrics_H\": metrics_H}\n",
    "\n",
    "output_path = \"./results/metrics_summary_50.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for sheet_name, metrics in metrics_dict.items():\n",
    "        pd.DataFrame([metrics]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/train_results_summary_50.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    train_results_D.to_excel(writer, sheet_name=\"Train_Results_D\", index=False)\n",
    "    train_results_P.to_excel(writer, sheet_name=\"Train_Results_P\", index=False)\n",
    "    train_results_H.to_excel(writer, sheet_name=\"Train_Results_H\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/test_results_summary_50.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    test_results_D.to_excel(writer, sheet_name=\"Test_Results_D\", index=False)\n",
    "    test_results_P.to_excel(writer, sheet_name=\"Test_Results_P\", index=False)\n",
    "    test_results_H.to_excel(writer, sheet_name=\"Test_Results_H\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results/out_results_summary_50.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    out_results_D.to_excel(writer, sheet_name=\"out_Results_D\", index=False)\n",
    "    out_results_P.to_excel(writer, sheet_name=\"out_Results_P\", index=False)\n",
    "    out_results_H.to_excel(writer, sheet_name=\"out_Results_H\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
